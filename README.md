# Introduction to Computer Music: Deep Music Generation

##### Ziyu Wang, NYU Shanghai

This is a *beginner-level* introduction to our two publications for disentangled music representations for monophonic and polyphonic music. This repository is originally made for the course *Introduction to Computer Music* at NYU Shanghai. It can also be served as a tutorial for other people who are interested to our projects and new to deep learning.

* **EC$^2$-VAE** for monophonic pitch contour and rhythm disentanglement. 

* **Poly-Dis** for polyphonic chord and texture disentanglement. 

We provide:

* The model architecture implemented in PyTorch. (The code is reformatted and **all the code for training is removed.**)
* (One-version of) the pre-trained model parameters. (Google drive links are provides inside `model_param` folders.)
* Sample data and a tutorial jupyter notebook.



## Reference

##### EC$^2$-VAE

* Ruihan Yang et al., "Deep Music Analogy Via Latent Representation Disentanglement", ISMIR 2019
* https://arxiv.org/abs/1906.03626
* https://github.com/buggyyang/Deep-Music-Analogy-Demos

##### Poly-Dis

* Ziyu Wang et al., "Learning Interpretable Representation for Controllable Polyphonic Music Generation", ISMIR 2020.
* Ziyu Wang et al., "PIANOTREE VAE: Structured Representation Learning for Polyphonic Music", ISMIR 2020
* https://github.com/ZZWaang/polyphonic-chord-texture-disentanglement
* https://github.com/ZZWaang/PianoTree-VAE
* https://program.ismir2020.net/poster_5-05.html
* https://program.ismir2020.net/poster_3-06.html